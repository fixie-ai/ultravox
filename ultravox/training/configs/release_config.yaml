# SLM with ultravox & llama3.1, trained wtih knowledge distillation.
# Make sure to accept the license agreement on huggingface hub
text_model: "meta-llama/Meta-Llama-3.1-8B-Instruct"
audio_model: "openai/whisper-medium"

loss_config:
  # Choose from ["KL_Divergence", "CrossEntropy"], default is "KL_Divergence"
  loss_function: "KL_Divergence"

train_sets:
  - name: librispeech-clean-continuation
  - name: librispeech-other-continuation
  - name: commonvoice-en-continuation

# Temporarily remove heysquad_human from val_sets as it causes the training to fail.
val_sets:
  - name: covost2-en-de
  - name: covost2-zh-en
  - name: peoplespeech-clean-transcription

batch_size: 24
max_steps: 14400 # x8x24 = 2,764,800
