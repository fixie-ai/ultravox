# closest trining data setup to v0.3, used for quick experiments and comparisons
# note: the audio_model is upgraded to whisper-large-v3-turbo instead of openai/whisper-medium

text_model: "meta-llama/Llama-3.1-8B-Instruct"
audio_model: "openai/whisper-large-v3-turbo"

train_sets:
  - name: librispeech-clean-continuation
  - name: librispeech-other-continuation
  - name: commonvoice-en-continuation


lr: 1e-3
lr_warmup_steps: 1000
batch_size: 12
grad_accum_steps: 2

max_steps: -1
num_epochs: 2
val_steps: 0.05
save_steps: 0.25

# the original v0.3 model is equivalent to projector_ln_mid: false
# use the default value here for projector_ln_mid: true
