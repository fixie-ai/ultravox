# SLM with ultravox & llama3, trained based on knowledge distillation.
exp_name: "llama3-whisper-s"

# Make sure to accept the license agreement on huggingface hub
text_model: "meta-llama/Meta-Llama-3-8B-Instruct"
audio_model: "openai/whisper-small"

batch_size: 16
max_steps: 100
lr_warmup_steps: 10

loss_config:
  # choose from ["KL_Divergence", "CrossEntropy"]
  loss_function: "KL_Divergence"

# use GenericVoiceDataset for loading continuation training data.
val_sets: []
data_sets: []
data_dicts:
  - path: "fixie-ai/librispeech_asr"
    name: "clean"
    splits:
      - "train.100"
      - "train.360"
    user_template: "Continue the following text using less than 50 words:\n\n<|audio|>"
    assistant_template: "{{ continuation }}"
    transcript_template: "{{ text }}"