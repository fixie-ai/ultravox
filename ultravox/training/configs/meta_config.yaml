text_model: "meta-llama/Meta-Llama-3-8B-Instruct"
audio_model: "facebook/wav2vec2-base-960h"

data_sets: ["gigaspeech"]
repeat_data: True

train_on_inputs: False
shuffle_data: True
max_audio_duration_secs: 16

val_num_samples: 128
val_steps: 500
eval_num_samples: 256
eval_max_new_tokens: 32
eval_num_procs: 16

optimizer: "adamw_torch"  # options: adamw_torch, adamw_bnb_8bit
lr_scheduler: "cosine"  # options: linear, cosine, cosine_with_restarts, etc.
lr:  2.e-3
grad_accum_steps: 1
lr_warmup_steps: 1000
max_steps: 10_000

save_steps: 0.25
logging_steps: 100

batch_size: 4
data_type: "bfloat16"

report_logs_to: ["tensorboard", "wandb"]
